version: '3.8'

services:
  # This is our Python development environment from the .devcontainer setup
  app:
    build:
      context: .
      dockerfile: .devcontainer/Dockerfile
    volumes:
      # Mounts the project directory into the container
      - ..:/home/circuidev/workspace:cached
    command: sleep infinity # Keeps the container running

  # This is the new service that runs the Ollama LLM server
  ollama:
    image: ollama/ollama
    volumes:
      # Persists the downloaded LLM models on your host machine
      - ollama-data:/root/.ollama
    ports:
      # Exposes the Ollama API to your host machine if needed
      - "11434:11434"

volumes:
  ollama-data:
